{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear, nonlinear, simple state spaces, complex state spaces\n",
    "# if the kde doesn't work, use a GP.\n",
    "\n",
    "# It's nan because you can't calculate the cosine distance of 0.0\n",
    "# Hyperparameters don't have a huge effect on the heatmap. The scale looks a little better with these though.\n",
    "# Looks like the result is any linear combination of the reward. So maybe modify the distance?\n",
    "# Larger grid doesn't really have an effect on it. Maybe larger state space would tho.\n",
    "# Uniform grid of reward function is much better. It's sort of cheating though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('../simulated_fqi/')\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import shap\n",
    "import configargparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import scipy\n",
    "from environments import Gridworld\n",
    "from models.agents import NFQAgent\n",
    "from models.networks import NFQNetwork, ContrastiveNFQNetwork\n",
    "from util import get_logger, close_logger, load_models, make_reproducible, save_models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from train import fqi\n",
    "import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "from environments import CartPoleRegulatorEnv\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from irl_gridworld import find_feature_expectations, plot_reward, norm, find_valid_actions, generate_rollout, generate_policy_rollout, runLinearFQI, l2_norm\n",
    "from multiprocessing import Pool\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biased data experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox = []\n",
    "for it in range(100):\n",
    "    r = np.random.normal(0.5, 0.5, 2)\n",
    "    behavior_opt, opt_agent = runLinearFQI(dataset='bg', behavior=True, reward_weights_shared=r)\n",
    "    ox.extend(behavior_opt)\n",
    "# Calculate posterior\n",
    "# Choose regular grid on -1 to 1 and 1 to 1\n",
    "x = np.arange(-1, 1.1, 0.1)\n",
    "x = np.around(x, decimals=1)\n",
    "y = np.arange(-1, 1.1, 0.1)\n",
    "y = np.around(y, decimals=1)\n",
    "\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "# The pairing of xx and yy gives the coordinates of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior = np.zeros((21, 21))\n",
    "heatmap_true = np.zeros((21, 21))\n",
    "for i in range(xx.shape[1]):\n",
    "    for j in range(yy.shape[0]):\n",
    "        r_j = [xx[0][i], yy[j][0]]\n",
    "        states = [list(r[0]) for r in behavior_opt]\n",
    "        rewards = [np.dot(r_j, list(s)) for s in states]\n",
    "        reward = sum(rewards)\n",
    "        \n",
    "        alpha = 0.001\n",
    "        density = multivariate_normal.pdf(r_j, mean=[0.5, 0.5], cov=[[0.5, 0], [0, 0.5]])\n",
    "        post = density * np.exp(alpha*reward)\n",
    "        #print(\"Density: \" + str(density) + \" Post: \" + str(np.exp(alpha * reward)) + \" Val: \" + str(post) + \" Reward: \" + str(r_j))\n",
    "        \n",
    "        heatmap_posterior[j, i] = post\n",
    "        heatmap_true[j, i] = density\n",
    "        \n",
    "#heatmap_posterior = np.divide(heatmap_posterior, np.sum(heatmap_posterior))\n",
    "ax = sns.heatmap(heatmap_posterior)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticklabels(x, rotation=90)\n",
    "ax.set_yticklabels(y, rotation=360)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# ax = sns.heatmap(heatmap_true)\n",
    "# ax.set_xticklabels(x, rotation=90)\n",
    "# ax.set_yticklabels(y, rotation=360)\n",
    "# ax.invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox = []\n",
    "r = [0.1, 0.1]\n",
    "for it in range(100):\n",
    "    behavior_opt, opt_agent = runLinearFQI(dataset='bg', reward_weights_shared=r, behavior=True)\n",
    "    ox.extend(behavior_opt)\n",
    "# Calculate posterior\n",
    "# Choose regular grid on -1 to 1 and 1 to 1\n",
    "x = np.arange(-1, 1.1, 0.1)\n",
    "y = np.arange(-1, 1.1, 0.1)\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "# The pairing of xx and yy gives the coordinates of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior = np.zeros((21, 21))\n",
    "heatmap_true = np.zeros((21, 21))\n",
    "for i in range(xx.shape[1]):\n",
    "    for j in range(yy.shape[0]):\n",
    "        r_j = [xx[0][i], yy[j][0]]\n",
    "        states = [list(r[0]) for r in behavior_opt]\n",
    "        rewards = [np.dot(r_j, list(s)) for s in states]\n",
    "        reward = sum(rewards)\n",
    "        \n",
    "        alpha = 0.001\n",
    "        density = multivariate_normal.pdf(r_j, mean=[0, 0], cov=[[1, 0], [0, 1]])\n",
    "        post = density * np.exp(alpha*reward)\n",
    "        #print(\"Density: \" + str(density) + \" Post: \" + str(np.exp(alpha * reward)) + \" Val: \" + str(post) + \" Reward: \" + str(r_j))\n",
    "        \n",
    "        heatmap_posterior[j, i] = post\n",
    "        heatmap_true[j, i] = density\n",
    "        \n",
    "ax = sns.heatmap(heatmap_posterior)\n",
    "ax.invert_yaxis()\n",
    "plt.show()\n",
    "plt.close()\n",
    "ax = sns.heatmap(heatmap_true)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a more accurate posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training reward functions evenly distributed\n",
    "def generate_observations(init_experience=5, n=4):\n",
    "    rewards = []\n",
    "    for i in range(-10, 11, 3):\n",
    "        for j in range(-10, 11, 3):\n",
    "            rewards.append([i/10, j/10])\n",
    "    \n",
    "    observations = []\n",
    "    for r in rewards:\n",
    "        behavior_opt, opt_agent = runLinearFQI(dataset='bg', init_experience=init_experience, behavior=True, reward_weights_shared=r, n=n)\n",
    "        for sample in behavior_opt:\n",
    "            s = (sample[0], sample[1], r)\n",
    "            observations.append(s)\n",
    "    return observations\n",
    "\n",
    "def distance_r(r, r_prime):\n",
    "    h_prime = 0.0012 # Proportional to standard deviation of all reward function distances (or variance)\n",
    "#     h_prime = 0.001 # Proportional to mean\n",
    "    h_prime = 0.05#149\n",
    "#     h=10e-3\n",
    "    dist = scipy.spatial.distance.cosine(r, r_prime)\n",
    "    return np.exp(-(np.power(dist, 2)/(2*h_prime)))\n",
    "\n",
    "def distance_points(p1, p2):\n",
    "    h = 0.326 # Proportional to standard deviation of all distances (or variance)\n",
    "#     h = 0.4093 # Proportional to mean\n",
    "    h = 0.032#32\n",
    "#     h=10e-3\n",
    "    # Removing the action part\n",
    "    dist = scipy.spatial.distance.euclidean(p1[0], p2[0]) #+ scipy.spatial.distance.euclidean(p1[1], p2[1])\n",
    "    return np.exp(-np.power(dist, 2)/(2*h))\n",
    "\n",
    "def distance_rewards(r_k, observations):\n",
    "    sum_diff = 0\n",
    "    for sample in observations:\n",
    "        r = sample[2]\n",
    "        sum_diff += distance_r(r_k, r)\n",
    "    return sum_diff\n",
    "\n",
    "def generate_dataset_plot(dataset, reward):\n",
    "    xs = [b[0][0] for b in dataset]\n",
    "    ys = [b[0][1] for b in dataset]\n",
    "    \n",
    "    heatmap_dataset = np.zeros((4, 4))\n",
    "    for i, x_i in enumerate(xs):\n",
    "        y_i = ys[i]\n",
    "        heatmap_dataset[y_i, x_i] += 1\n",
    "    \n",
    "    heatmap_dataset /= np.max(np.abs(heatmap_dataset))\n",
    "    x = np.arange(0, 4, 1)\n",
    "    y = np.arange(0, 4, 1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(5)\n",
    "    ax = sns.heatmap(heatmap_dataset)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(x, rotation=90)\n",
    "    ax.set_yticklabels(y, rotation=360)\n",
    "#     plt.title(\"Demonstration density\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return heatmap_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating what h and hprime should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = generate_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = []\n",
    "for s in observations:\n",
    "    for s_prime in observations:\n",
    "        r = s[2]\n",
    "        r_prime = s_prime[2]\n",
    "        all_distances.append(distance_r(r, r_prime))\n",
    "sns.distplot(all_distances)\n",
    "print(\"var distance: \", np.std(all_distances)*np.std(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = []\n",
    "for o in observations:\n",
    "    for o_prime in observations:\n",
    "        all_distances.append(distance_points(o, o_prime))\n",
    "sns.distplot(all_distances)\n",
    "print(\"var distance: \", np.std(all_distances)*np.std(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 1.1, 0.2)\n",
    "x = np.around(x, decimals=1)\n",
    "y = np.arange(-1, 1.1, 0.2)\n",
    "y = np.around(y, decimals=1)\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_post(r_k):\n",
    "    # Product\n",
    "    post = 1\n",
    "    prior = multivariate_normal.pdf(r_k, mean=[0, 0], cov=[[1, 0], [0, 1]])\n",
    "    dist_rewards = distance_rewards(r_k)\n",
    "    for s_i in observations:\n",
    "        # Sum\n",
    "        sum_si = 0\n",
    "        for s_j in observations:\n",
    "            likelihood = distance_points(s_i, s_j) * distance_r(r_k, s_i[2]) / dist_rewards\n",
    "            sum_si += likelihood * prior\n",
    "        post *= sum_si\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior = np.zeros((11, 11))\n",
    "all_rks = []\n",
    "for kk, i in enumerate(tqdm.tqdm(range(xx.shape[1]))):\n",
    "    for j in range(yy.shape[0]):\n",
    "        # Evaluate the posterior at this reward parameter\n",
    "        r_k = [xx[0][i], yy[j][0]]\n",
    "        post = estimate_post(r_k)\n",
    "        heatmap_posterior[j, i] = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax = sns.heatmap(heatmap_posterior)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xticklabels(x, rotation=90)\n",
    "ax.set_yticklabels(y, rotation=360)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert trajectories\n",
    "* TODO: parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_dist(s_i, dataset, reward):\n",
    "    sum = 0\n",
    "    dist_rewards = distance_rewards(reward, dataset)\n",
    "    sum_weights = 0\n",
    "    count_p = 0\n",
    "    for s_j in dataset:\n",
    "        weight = distance_r(reward, s_j[2]) / dist_rewards\n",
    "        dist = distance_points(s_i, s_j)\n",
    "        est = dist * weight \n",
    "        sum += est\n",
    "#     h = 0.003\n",
    "#     h_prime = 0.05\n",
    "#     sum /= np.sqrt(np.power(2*np.pi, 2) * h) * np.sqrt(np.power(2*np.pi, 2) * h_prime)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_expert_prior(r_k, behavior_opt, observations):\n",
    "    post = 0\n",
    "    dist_rewards = distance_rewards(r_k, observations)\n",
    "    for s_i in behavior_opt:\n",
    "        # Sum\n",
    "#         post += np.log(conditional_dist(s_i, behavior_opt, r_k))\n",
    "        sum_si = 0\n",
    "        for s_j in observations:\n",
    "            weight = distance_r(r_k, s_j[2]) / dist_rewards\n",
    "            likelihood = distance_points(s_i, s_j) * weight\n",
    "            sum_si += likelihood\n",
    "#         h = 0.003\n",
    "#         h_prime = 0.05\n",
    "#         sum_si /= np.sqrt(np.power(2*np.pi, 2) * h) * np.sqrt(np.power(2*np.pi, 2) * h_prime)\n",
    "        if sum_si == 0:\n",
    "            post += np.log(0.000000000001)\n",
    "        else:\n",
    "            post += np.log(sum_si)\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = generate_observations(init_experience=10, n=4)\n",
    "print(str(len(observations)))\n",
    "behavior_opt, opt_agent = runLinearFQI(dataset='bg', init_experience=10, behavior=True, reward_weights_shared=[1, 1], n=4)\n",
    "print(str(len(behavior_opt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional density estimation\n",
    "def heatmap_dataset_conditional_density_posterior(reward, plot=True):\n",
    "    x = np.arange(-1, 1.1, 0.2)\n",
    "    x = np.around(x, decimals=1)\n",
    "    y = np.arange(-1, 1.1, 0.2)\n",
    "    y = np.around(y, decimals=1)\n",
    "    xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    # n observations\n",
    "    observations = generate_observations(init_experience=10, n=4)\n",
    "    # m expert observations\n",
    "    behavior_opt, opt_agent = runLinearFQI(dataset='bg', init_experience=10, behavior=True, reward_weights_shared=reward, n=4)\n",
    "    \n",
    "    if plot:\n",
    "        heatmap_dataset = generate_dataset_plot(behavior_opt, reward)\n",
    "\n",
    "        x = np.arange(0, 4, 1)\n",
    "        y = np.arange(0, 4, 1)\n",
    "        xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "        heatmap_conditional = np.zeros((4, 4))\n",
    "        action_pos_dict = {1: [-1, 0], 2: [1, 0], 3: [0, -1], 4: [0, 1]}\n",
    "        xs = []\n",
    "        ys = []\n",
    "        zs = []\n",
    "        conditional_est = []\n",
    "        for a in [1, 2, 3, 4]:\n",
    "            action = action_pos_dict[a]\n",
    "            for kk, i in enumerate(tqdm.tqdm(range(xx.shape[1]))):\n",
    "                for j in range(yy.shape[0]):\n",
    "                    # Evaluate the posterior at this reward parameter\n",
    "                    state = ([xx[0][i], yy[j][0]], action)\n",
    "                    c_est = conditional_dist(state, observations, reward)\n",
    "                    conditional_est.append(c_est)\n",
    "                    heatmap_conditional[j, i] += c_est\n",
    "        fig = plt.figure()\n",
    "        fig.set_figheight(5)\n",
    "        fig.set_figwidth(5)\n",
    "        ax = sns.heatmap(heatmap_conditional)\n",
    "#         plt.title(\"Conditional density for reward=\" + str(reward))\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xticklabels(x, rotation=90)\n",
    "        ax.set_yticklabels(y, rotation=360)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        x = np.arange(-1, 1.1, 0.2)\n",
    "        x = np.around(x, decimals=1)\n",
    "        y = np.arange(-1, 1.1, 0.2)\n",
    "        y = np.around(y, decimals=1)\n",
    "        xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "        # n observations\n",
    "        # m expert observations\n",
    "        heatmap_posterior = np.zeros((11, 11))\n",
    "        all_rks = []\n",
    "        for kk, i in enumerate(tqdm.tqdm(range(xx.shape[1]))):\n",
    "            for j in range(yy.shape[0]):\n",
    "                # Evaluate the posterior at this reward parameter\n",
    "                r_k = [xx[0][i], yy[j][0]]\n",
    "                post = estimate_expert_prior(r_k, behavior_opt, observations)\n",
    "                heatmap_posterior[j, i] = post\n",
    "        fig = plt.figure()\n",
    "        fig.set_figheight(5)\n",
    "        fig.set_figwidth(5)\n",
    "        ax = sns.heatmap(heatmap_posterior)\n",
    "        ax.invert_yaxis()\n",
    "        plt.xlabel(\"Reward parameter 1\")\n",
    "        plt.ylabel(\"Reward parameter 2\")\n",
    "#         plt.title(\"Expert posterior, true reward=\" + str(reward))\n",
    "        ax.set_xticklabels(x, rotation=90)\n",
    "        ax.set_yticklabels(y, rotation=360)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    else:\n",
    "        x = np.arange(-1, 1.1, 0.2)\n",
    "        x = np.around(x, decimals=1)\n",
    "        y = np.arange(-1, 1.1, 0.2)\n",
    "        y = np.around(y, decimals=1)\n",
    "        xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "        # n observations\n",
    "        # m expert observations\n",
    "        heatmap_posterior = np.zeros((11, 11))\n",
    "        all_rks = []\n",
    "        for kk, i in enumerate(tqdm.tqdm(range(xx.shape[1]))):\n",
    "            for j in range(yy.shape[0]):\n",
    "                # Evaluate the posterior at this reward parameter\n",
    "                r_k = [xx[0][i], yy[j][0]]\n",
    "                post = estimate_expert_prior(r_k, behavior_opt, observations)\n",
    "                heatmap_posterior[j, i] = post\n",
    "#         heatmap_posterior /= np.max(np.abs(heatmap_posterior))\n",
    "    return heatmap_posterior\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward(n=4, title='Reward = x + y', reward_params=None):\n",
    "    reward_matrix = np.zeros((n, n))\n",
    "    positions = [i for i in range(n)]\n",
    "    for i, x in enumerate(range(n)):\n",
    "        for j, y in enumerate(range(n)):\n",
    "            reward = x*reward_params[0] + y*reward_params[1]\n",
    "            reward_matrix[j,i] = reward\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    reward_matrix /= np.max(np.abs(reward_matrix))\n",
    "    ax = sns.heatmap(reward_matrix, xticklabels=positions, yticklabels=positions)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    ax.invert_yaxis()\n",
    "    #plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_reward(reward_params=[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior = heatmap_dataset_conditional_density_posterior([-1, 1], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap_posterior = heatmap_posterior.copy()\n",
    "# hmap_posterior[5][5] = -83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap_posterior[5][5] = -74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap_posterior = (hmap_posterior - np.min(hmap_posterior))/np.ptp(hmap_posterior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 1.1, 0.2)\n",
    "x = np.around(x, decimals=1)\n",
    "y = np.arange(-1, 1.1, 0.2)\n",
    "y = np.around(y, decimals=1)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "ax = sns.heatmap(hmap_posterior)\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel(\"Reward parameter 1\")\n",
    "plt.ylabel(\"Reward parameter 2\")\n",
    "#         plt.title(\"Expert posterior, true reward=\" + str(reward))\n",
    "ax.set_xticklabels(x, rotation=90)\n",
    "ax.set_yticklabels(y, rotation=360)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the posterior, then use that sample to calculate reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_posterior[5][5] = -74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = heatmap_posterior / np.max(np.abs(heatmap_posterior))\n",
    "post = np.exp(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(post)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post /= np.sum(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.random.multinomial(1000000, post.flatten())\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = rewards.reshape((11, 11))\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(rewards)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(rewards // 1000)\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = rewards // 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = np.flip(evaluations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1, 1.1, 0.2)\n",
    "x = np.around(x, decimals=1)\n",
    "y = np.arange(-1, 1.1, 0.2)\n",
    "y = np.around(y, decimals=1)\n",
    "rewards = []\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "for kk, i in enumerate(tqdm.tqdm(range(11))):\n",
    "    for ll, j in enumerate(range(11)):\n",
    "        r_k = [xx[0][i], yy[j][0]]\n",
    "        count = evaluations[ll, kk]\n",
    "        for aa in range(count):\n",
    "            rewards.append(r_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hmaps = np.zeros((1, 4, 4))\n",
    "n = 4\n",
    "for r in rewards:\n",
    "    reward_matrix = np.zeros((4, 4))\n",
    "    for i, x in enumerate(range(n)):\n",
    "        for j, y in enumerate(range(n)):\n",
    "            reward = x*r[0] + y*r[1]\n",
    "            reward_matrix[j,i] = reward\n",
    "    all_hmaps = np.append(all_hmaps, np.asarray([reward_matrix]), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hmap = np.mean(all_hmaps[1:], axis=0)\n",
    "mean_hmap = (mean_hmap - np.min(mean_hmap))/np.ptp(mean_hmap)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "ax = sns.heatmap(mean_hmap)\n",
    "# ax.invert_yaxis()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "# plt.title(\"Reward Mean Scaled\")\n",
    "ax.set_xticklabels([0, 1, 2, 3], rotation=90)\n",
    "ax.set_yticklabels([0, 1, 2, 3], rotation=360)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_hmap = np.std(all_hmaps[1:], axis=0)\n",
    "std_hmap /= np.max(np.abs(std_hmap))\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "ax = sns.heatmap(std_hmap)\n",
    "# ax.invert_yaxis()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "# plt.title(\"Reward SD Scaled\")\n",
    "ax.set_xticklabels([0, 1, 2, 3], rotation=90)\n",
    "ax.set_yticklabels([0, 1, 2, 3], rotation=360)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research [~/.conda/envs/research/]",
   "language": "python",
   "name": "conda_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
